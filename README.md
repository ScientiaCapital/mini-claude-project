# Mini-Claude: Build Your Own AI Assistant

An educational project to learn transformer architecture, LoRA fine-tuning, and modern AI development through building a functional chatbot.

## Overview

Mini-Claude is a hands-on learning project that teaches you how to build an AI assistant from scratch. Following Test-Driven Development (TDD) principles, you'll implement:

- ðŸ¤– A working chatbot using pre-trained models
- ðŸ§  Understanding of transformer architecture
- ðŸ”§ LoRA (Low-Rank Adaptation) for efficient fine-tuning
- ðŸŽ¨ Modern web interface with Gradio
- ðŸ“š Integration with educational repositories

## Installation

1. Clone this repository:
```bash
git clone https://github.com/yourusername/mini-claude.git
cd mini-claude
```

2. Create a virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## Quick Start

1. Download required models (first time only):
```bash
# Using HuggingFace CLI (recommended)
huggingface-cli download microsoft/DialoGPT-medium

# Or use our download script
python scripts/download_models.py
```

2. Run the MVP chatbot:
```bash
python src/mvp_chatbot.py
```

3. For the web interface:
```bash
python src/web_app.py
```

## Project Structure

```
mini-claude/
â”œâ”€â”€ src/                    # Core source code
â”‚   â”œâ”€â”€ models/            # Model implementations
â”‚   â”œâ”€â”€ training/          # Training scripts
â”‚   â””â”€â”€ web/               # Web interface
â”œâ”€â”€ tests/                  # Test suite (TDD)
â”‚   â”œâ”€â”€ unit/              # Unit tests
â”‚   â””â”€â”€ integration/       # Integration tests
â”œâ”€â”€ data/                   # Training datasets
â”œâ”€â”€ notebooks/              # Learning notebooks
â”œâ”€â”€ resources/              # Learning materials
â”‚   â””â”€â”€ repos/             # Cloned repositories
â””â”€â”€ docs/                   # Documentation
```

## Learning Path

This project follows a 12-week learning journey:

- **Weeks 1-2**: Basic chatbot and Gradio interface
- **Weeks 3-4**: Understanding transformers from scratch
- **Weeks 5-6**: Implementing LoRA fine-tuning
- **Weeks 7-8**: Training pipeline and evaluation
- **Weeks 9-10**: Advanced features (memory, streaming)
- **Weeks 11-12**: Production optimization and deployment

## Key Learning Resources

This project integrates concepts from:
- `rasbt/LLMs-from-scratch` - Core transformer education
- `huggingface/course` - Industry best practices
- `jaymody/picoGPT` - Minimal GPT implementation
- `AK391/ai-gradio` - Quick UI prototyping
- `hiyouga/LLaMA-Factory` - Advanced fine-tuning

## Testing

We follow strict TDD principles. Run tests with:

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src tests/

# Run specific test category
pytest tests/unit/
```

## Contributing

This is an educational project. Feel free to:
- Report issues
- Suggest improvements
- Share your learning experience

## License

MIT License - see LICENSE file for details.

## Acknowledgments

Built as an educational project inspired by Claude and the open-source AI community.